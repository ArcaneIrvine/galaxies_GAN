{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from keras.utils import np_utils\n",
    "from keras import utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### avoid oom errors by setting gpu memory consumption growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab all the gpus available in the machine\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for every gpu set memory growth (making tensorflow to keep the memory only to what it needs)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using the Galaxy10 SDSS Dataset from [astroNN](https://astronn.readthedocs.io/en/latest/index.html). The dataset can be found here: http://www.astro.utoronto.ca/~bovy/Galaxy10/Galaxy10.h5  \n",
    "The dataset contains 21785 69x69 pixels colored galaxy images separated in 10 classes as shown below:  \n",
    "\n",
    "Galaxy10 dataset (21785 images)  \n",
    "├── Class 0 (3461 images): Disk, Face-on, No Spiral  \n",
    "├── Class 1 (6997 images): Smooth, Completely round  \n",
    "├── Class 2 (6292 images): Smooth, in-between round  \n",
    "├── Class 3 (394 images): Smooth, Cigar shaped  \n",
    "├── Class 4 (1534 images): Disk, Edge-on, Rounded Bulge  \n",
    "├── Class 5 (17 images): Disk, Edge-on, Boxy Bulge  \n",
    "├── Class 6 (589 images): Disk, Edge-on, No Bulge  \n",
    "├── Class 7 (1121 images): Disk, Face-on, Tight Spiral  \n",
    "├── Class 8 (906 images): Disk, Face-on, Medium Spiral  \n",
    "└── Class 9 (519 images): Disk, Face-on, Loose Spiral  \n",
    "\n",
    "Images come from [Sloan Digital Sky Survey](https://www.sdss.org/) and labels from [Galaxy Zoo](https://www.zooniverse.org/projects/zookeeper/galaxy-zoo/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the images and labels from file\n",
    "with h5py.File('dataset/Galaxy10.h5', 'r') as F:\n",
    "    images = np.array(F['images'])\n",
    "    labels = np.array(F['ans'])\n",
    "\n",
    "# convert the labels to categorical 10 classes\n",
    "labels = utils.to_categorical(labels, 10)\n",
    "\n",
    "# convert to desirable type\n",
    "labels = labels.astype(np.uint8)\n",
    "images = images.astype(np.uint8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 16 random images\n",
    "num_images = images.shape[0]\n",
    "random_images = random.sample(range(num_images), 16)\n",
    "# get their corresponding labels\n",
    "img = images[random_images]\n",
    "random_labels = [str(label) for label in labels[random_images]]\n",
    "\n",
    "# visualize them\n",
    "fig, ax = plt.subplots(ncols=4, nrows=4, figsize=(20,20))\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        ax[i][j].imshow(img[(i+1)*(j+1)-1])\n",
    "        ax[i][j].title.set_text(random_labels[(i+1)*(j+1)-1])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(image):\n",
    "    # resize the image to 68x68\n",
    "    image = tf.image.resize(image, size=(68, 68))\n",
    "    # scale the image\n",
    "    image = image / 255\n",
    "    # return the processed image\n",
    "    return image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cache/shuffle/batch/prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numpy array to a `tf.data.Dataset` object\n",
    "images = tf.data.Dataset.from_tensor_slices(images)\n",
    "\n",
    "# run images through the preprocess function\n",
    "images = images.map(preprocess_images)\n",
    "# cache images for that batch\n",
    "images = images.cache()\n",
    "# shuffle the images\n",
    "images = images.shuffle(60000)\n",
    "# batch them into 128 images per sample\n",
    "images = images.batch(128)\n",
    "# reduces the likelihood of bottlenecking\n",
    "images = images.prefetch(64)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Generator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the GAN model we need a generator. The generator's purpose is to take random noise as input and generate new samples that are similar to the training data (meaning our images from the dataset). By doing so the generator can then fool the discriminator (which we will also build later) into thinking they are real data samples. The goal is for the generator to \"compete\" with the discriminator and over time both of them get better and better. If the generator is not able to \"fool\" the discriminator it means that the sample is not very realistic and needs further improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the modeling components\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Flatten, Reshape, LeakyReLU, Dropout, UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    model = Sequential()                       # define our model\n",
    "    model.add(Dense(17*17*128, input_dim=128)) # add Dense layer with random noise as input\n",
    "    model.add(LeakyReLU(0.2))                  # apply LeakyRelu activation\n",
    "    model.add(Reshape((17,17,128)))            # reshape to 17*17*128\n",
    "\n",
    "    # Upsampling block - 1\n",
    "    model.add(UpSampling2D())                  # layer used to increase the spatial resolution of the input\n",
    "    model.add(Conv2D(128, 5, padding='same'))  # convolutional nn layer with 128 units, kernel size 5x5 and padding same\n",
    "    model.add(LeakyReLU(0.2))                  # apply LeakyRelu activation\n",
    "\n",
    "    # Upsampling block - 2\n",
    "    model.add(UpSampling2D())                  # layer used to increase the spatial resolution of the input\n",
    "    model.add(Conv2D(128, 5, padding='same'))  # convolutional nn layer with 128 units, kernel size 5x5 and padding same\n",
    "    model.add(LeakyReLU(0.2))                  # apply LeakyRelu activation\n",
    "\n",
    "    # Downsampling block - 1\n",
    "    model.add(Conv2D(128, 4, padding='same'))  # convolutional nn layer with 128 units, kernel size 4x4 and padding same\n",
    "    model.add(LeakyReLU(0.2))                  # apply LeakyRelu activation\n",
    "\n",
    "    # Downsampling block - 2\n",
    "    model.add(Conv2D(128, 4, padding='same'))  # convolutional nn layer with 128 units, kernel size 4x4 and padding same\n",
    "    model.add(LeakyReLU(0.2))                  # apply LeakyRelu activation\n",
    "\n",
    "    # convolutional nn layer to change to 3 channels,kernel size 4x4, same padding and a sigmoid activation this time\n",
    "    model.add(Conv2D(3, 4, padding='same', activation='sigmoid'))\n",
    "\n",
    "    # return the model\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator()\n",
    "generator.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 4 random images\n",
    "imgs = generator.predict(np.random.randn(4, 128), verbose=0)\n",
    "# get data out of the pipeline and visualize\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "# loop through images\n",
    "for idx, img in enumerate(imgs):\n",
    "    ax[idx].imshow(np.squeeze(img))\n",
    "    ax[idx].title.set_text(idx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Discriminator"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the GAN model we also need a discriminator. The discriminator's purpose is distinguishing between the generated (meaning the fake images) and the real images. It is trained to classify images as either real or fake and its feedback is used to train the generator and produce even better images. By training them simultaneously the GAN model is able to generate better and better images over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = Sequential()                            # define our model\n",
    "\n",
    "    # convolutional block - 1\n",
    "    model.add(Conv2D(32, 5, input_shape=(68,68,3))) # convolutional nn layer with 32 units, kernel size 5x5 and input size of our data\n",
    "    model.add(LeakyReLU(0.2))                       # apply LeakyRelu activation\n",
    "    model.add(Dropout(0.4))                         # apply Dropout for reguralizaion (prevents overfitting)\n",
    "\n",
    "    # convolutional block - 2\n",
    "    model.add(Conv2D(64, 5))                        # convolutional nn layer with 64 units, kernel size 5x5\n",
    "    model.add(LeakyReLU(0.2))                       # apply LeakyRelu activation\n",
    "    model.add(Dropout(0.4))                         # apply Dropout for reguralizaion (prevents overfitting)\n",
    " \n",
    "    # convolutional block - 3\n",
    "    model.add(Conv2D(128, 5))                       # convolutional nn layer with 128 units, kernel size 5x5\n",
    "    model.add(LeakyReLU(0.2))                       # apply LeakyRelu activation\n",
    "    model.add(Dropout(0.4))                         # apply Dropout for reguralizaion (prevents overfitting)\n",
    "\n",
    "    # convolutional block - 4\n",
    "    model.add(Conv2D(128, 5))                       # convolutional nn layer with 128 units, kernel size 5x5\n",
    "    model.add(LeakyReLU(0.2))                       # apply LeakyRelu activation\n",
    "    model.add(Dropout(0.4))                         # apply Dropout for reguralizaion (prevents overfitting)\n",
    "\n",
    "    # flatten and then pass to one Dense layer\n",
    "    model.add(Flatten())                            # Flattens output (takes the output of the last convolutional layer and converts from 3D tensor to 1D tensor)\n",
    "    model.add(Dropout(0.4))                         # apply Dropout for reguralizaion (prevents overfitting)\n",
    "    model.add(Dense(1, activation='sigmoid'))       # Dense layer for final decision based on the features learned by the previous layers (1 for false image and 0 for real image)\n",
    "\n",
    "    # return the model\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_discriminator()\n",
    "discriminator.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use discriminator to make predictions on the 4 generated images from earlier\n",
    "discriminator.predict(imgs, verbose=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training loop components\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam optimizers for generator and discriminator (determine how quickly the weights of the model are updated during training)\n",
    "gen_opt = Adam(learning_rate=0.0001)  # learning rate for generator optimizer set to 0.0001\n",
    "dis_opt = Adam(learning_rate=0.00001) # learning rate for discriminator optimizer set to 0.00001\n",
    "\n",
    "# Losses for generator and discriminator (measure how well the model is performing)\n",
    "gen_loss = BinaryCrossentropy()\n",
    "dis_loss = BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build subclassed model\n",
    "class galaxyGAN(Model):\n",
    "    def __init__(self, generator, discriminator, *args, **kwargs):\n",
    "        # pass through args and kwargs to base class\n",
    "        super().__init__(*args, **kwargs)\n",
    "        # create attributes for generator and discriminator\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "    \n",
    "    def compile(self, gen_opt, dis_opt, gen_loss, dis_loss, *args, **kwargs):\n",
    "        # compile with base class\n",
    "        super().compile(*args, **kwargs)\n",
    "        # create attributes for losses and optimizers\n",
    "        self.gen_opt = gen_opt\n",
    "        self.dis_opt = dis_opt\n",
    "        self.gen_loss = gen_loss\n",
    "        self.dis_loss = dis_loss\n",
    "    \n",
    "    # Train step\n",
    "    def train_step(self, batch):\n",
    "        # get data\n",
    "        real_img = batch\n",
    "        fake_img = self.generator(tf.random.normal((128, 128, 1)), training=False)\n",
    "\n",
    "        # Train discriminator\n",
    "        with tf.GradientTape() as dis_tape:\n",
    "            # pass real and fake images to discriminator\n",
    "            real = self.discriminator(real_img, training=True)                                  # get real images\n",
    "            fake = self.discriminator(fake_img, training=True)                                  # get fake images\n",
    "            real_fake = tf.concat([real, fake], axis=0)                                         # concatenates the output of the discriminator for fake and real images as a single tensor\n",
    "\n",
    "            # create labels for real and fake images (0 for real and 1 for fake)\n",
    "            real_fake_labels = tf.concat([tf.zeros_like(real), tf.ones_like(fake)], axis=0)\n",
    "\n",
    "            # add some noise to the outputs (to prevent overfitting and improve the generalization performance of the model)\n",
    "            noise_real = 0.15*tf.random.uniform(tf.shape(real))                                 # 0.15 for real samples (swifted up)\n",
    "            noise_fake = -0.15*tf.random.uniform(tf.shape(fake))                                # -0.15 for fake samples (swifted down)\n",
    "            real_fake_labels = tf.concat([noise_real, noise_fake], axis=0)                      # concatenates the output of the real and fake noise as a single tensor\n",
    "\n",
    "            # calcualte loss\n",
    "            total_dis_loss = self.dis_loss(real_fake_labels, real_fake)\n",
    "\n",
    "            # apply backpropagation (allow NN to learn)\n",
    "            disgrad = dis_tape.gradient(total_dis_loss, self.discriminator.trainable_variables) # computes the gradients of the total discriminator loss with respect to its trainable variables\n",
    "            self.dis_opt.apply_gradients(zip(disgrad, self.discriminator.trainable_variables))  # apply the computed gradients to the discriminator's trainable variables using the optimizer\n",
    "        \n",
    "        # Train generator\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            # generate some new images\n",
    "            gen_img = self.generator(tf.random.normal((128, 128, 1)), training=True)            # creates a tensor of shape (128,128,1) and passes it to the generator network\n",
    "            pred_labels = self.discriminator(gen_img, training=False)                           # gets the predicted values for the generated images (if they are fake or real)\n",
    "            total_gen_loss = self.gen_loss(tf.zeros_like(pred_labels), pred_labels)             # calculates generator's loss \n",
    "        \n",
    "        # apply backpropagation (allow NN to learn)\n",
    "        gengrad = gen_tape.gradient(total_gen_loss, self.generator.trainable_variables)         # computes the gradients of the total generator loss with respect to its trainable variables\n",
    "        self.gen_opt.apply_gradients(zip(gengrad, self.generator.trainable_variables))          # apply the computed gradients to the generator's trainable variables using the optimizer\n",
    "\n",
    "        # return losses\n",
    "        return {'discriminator loss':total_dis_loss, 'generator loss':total_gen_loss}\n",
    "    \n",
    "    # Test step\n",
    "    def test_step(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instant of the GAN\n",
    "galaxygan = galaxyGAN(generator, discriminator)\n",
    "\n",
    "# compile the model (specify the optimizer and loss functions for both generator and discriminator)\n",
    "galaxygan.compile(gen_opt, dis_opt, gen_loss, dis_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the callback components\n",
    "import os\n",
    "from keras.utils import array_to_img\n",
    "from keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The call back function allows us to save examples of our generated images as we are training\n",
    "class ModelMonitor(Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        # generate random values\n",
    "        random_latent_vectors = tf.random.uniform((self.num_img, self.latent_dim,1))\n",
    "        # pass to generator\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        # generate bunch of images\n",
    "        generated_images *= 255\n",
    "        # convert them to a numpy array\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = array_to_img(generated_images[i])\n",
    "            img.save(os.path.join('images', f'generated_img_{epoch}_{i}.png'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the GAN with 1 epochs and our callback function (alot more epochs needed for a good model, ideally 2000)\n",
    "hist = galaxygan.fit(images, epochs=1, callbacks=[ModelMonitor()])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.suptitle('Loss')\n",
    "plt.plot(hist.history['dis_loss'], label='dis_loss')\n",
    "plt.plot(hist.history['gen_loss'], label='gen_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "048b82432893db2d39e857850310c8d5e6640b3b7bbabb57cf078719cf549466"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
